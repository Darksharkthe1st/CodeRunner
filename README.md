# CodeRunner

Full-stack web IDE for writing, compiling, and executing code in multiple languages. Built with **React** and **Spring Boot** with **Docker** containerization and **LangChain4j AI agent** for intelligent code assistance.

**LIVE**: [https://code-runner-eta.vercel.app/](https://code-runner-eta.vercel.app/)

## Features

### Core Functionality
- **Multi-Language Support**: Java, Python, and C with full execution
- **Asynchronous Execution**: 10-worker thread pool with UUID-based polling
- **Docker Containerization**: Isolated execution environment for all languages
- **Syntax Highlighting**: Custom regex-based highlighter
- **60s Timeout & Output Limits**: Protection against abuse and memory overflow

### AI-Powered Code Assistant
- **LangChain4j Agent**: Google Gemini 2.5 Flash with @AiService and @Tool annotations
- **Autonomous Code Testing**: Agent can execute test code to verify fixes
- **Context-Aware**: Full access to code, chat history, and execution results
- **Read-Only Design**: Suggests fixes, user manually applies changes
- **Markdown Rendering**: Syntax-highlighted responses in chat interface

### User Interface
- **Split-Pane Layout**: Code editor + output console with resizable dividers
- **Dark/Light Mode**: Terminal-style theme toggle
- **Tab Interface**: Input and Code_Helper tabs with persistent chat
- **Font Adjustments**: Zoom controls for comfortable reading
- **Visual Feedback**: Execution animations and error alerts

## Tech Stack

### Frontend
- **React 19** + **Vite** + **Tailwind CSS**
- **react-markdown** + **remark-gfm** for AI response rendering
- Custom regex-based syntax highlighter

### Backend
- **Spring Boot 4.0.1** + **Java 21** + **Maven**
- **Docker** for containerized code execution
- **LangChain4j 1.11.0-beta19** with @AiService and @Tool support
- **Google Gemini 2.5 Flash** LLM integration
- **ExecutorService** (10-worker thread pool) + **ConcurrentHashMap** for async queue

## Architecture

CodeRunner uses a modern **asynchronous execution queue model** with **LangChain4j agent framework** for intelligent code assistance.

### Execution Service & Queue Model

```
User Submission â†’ UUID Generated â†’ Submitted to Queue (10 worker threads) â†’
Async Execution â†’ Docker Container â†’ Output Collection â†’
Poll for Results (RUNNING/FINISHED) â†’ Cleanup
```

- 10-worker `ExecutorService` thread pool for concurrent executions
- UUID-based tracking with `ConcurrentHashMap`
- Non-blocking submit, frontend polls `/check` every 500ms
- Scheduled cleanup removes executions older than 60s (runs every 30s)

### Request Flow (IDE Execution)
1. Frontend â†’ `POST /submit` â†’ `CodeExecutionService` creates thread + UUID
2. UUID returned immediately (non-blocking)
3. Frontend polls `POST /check` with UUID every 500ms
4. Worker executes in Docker (Java/Python/C containers)
5. Results returned as `RunResult` with status: RUNNING/FINISHED/NONEXISTENT

### AI Assistant Flow (Agent with Tool Invocation)

```
User Message â†’ /llm/message â†’ GeminiService â†’ CodeHelperAssistant.chat() â†’
Gemini 2.5 Flash analyzes context + chat history â†’
[OPTIONAL] Agent invokes CodeExecutionTools.executeCode() â†’
Tool submits to same execution queue â†’ Poll for results â†’ Tool returns output â†’
Agent interprets results â†’ Generates debugging advice â†’ Returns to user
```

- `CodeHelperAssistant` (@AiService) with system prompt defines agent behavior
- Agent invokes `@Tool` methods to autonomously test code
- Full context awareness: chat history + code + execution results
- Read-only design: suggests fixes, doesn't modify user code
- Output truncated to 1MB to prevent token overflow

### Agent Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LangChain4j Framework                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CodeHelperAssistant (@AiService)                           â”‚
â”‚  â”œâ”€â”€ System Prompt + chat(List<ChatMessage>)               â”‚
â”‚  â””â”€â”€ Auto-wired to ChatModel bean                           â”‚
â”‚                                                              â”‚
â”‚  CodeExecutionTools (@Component)                            â”‚
â”‚  â”œâ”€â”€ @Tool: executeCode(code, language, input)             â”‚
â”‚  â””â”€â”€ Submits to CodeExecutionService, polls, returns output â”‚
â”‚                                                              â”‚
â”‚  LLMConfig (@Configuration)                                 â”‚
â”‚  â””â”€â”€ Creates ChatModel bean (gemini-2.5-flash)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                  CodeExecutionService
```

### Old vs. New Architecture Comparison

| Aspect | Old Architecture | New Architecture |
|--------|------------------|------------------|
| **Execution Model** | Synchronous, blocking | Async queue with 10-worker thread pool |
| **Concurrency** | Single request blocks thread | Up to 10 parallel executions |
| **Result Tracking** | Direct response | UUID-based polling with ConcurrentHashMap |
| **Memory Management** | On-demand cleanup | Fixed pool + scheduled 30s cleanup |
| **LLM Integration** | Direct Gemini API calls | LangChain4j @AiService agent |
| **Code Testing** | Manual user testing only | Agent can autonomously execute test code |
| **Tool Framework** | N/A | @Tool methods for agent capabilities |
| **Context Building** | Simple message concatenation | Structured ChatMessage with code context injection |
| **Scalability** | Limited by sequential execution | Horizontal scalability with thread pool |
| **Response Time** | Waits for full execution | Immediate UUID return, async polling |

### Complete Data Flow

#### IDE User Flow (Direct Code Execution)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User     â”‚
â”‚  Browser   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 1. POST /submit {code, language, input}
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     IDEController.postSubmission()      â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 2. Create CodeExecution thread
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CodeExecutionService.execute()         â”‚
â”‚  â€¢ Generate UUID                        â”‚
â”‚  â€¢ Store in ConcurrentHashMap           â”‚
â”‚  â€¢ Submit to ExecutorService pool       â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 3. Return UUID immediately
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend  â”‚â”€â”€â”€â”€â–¶â”‚  Worker Thread (1 of 10)     â”‚
â”‚  Polls     â”‚     â”‚  â€¢ CodeExecution.run()       â”‚
â”‚  /check    â”‚     â”‚  â€¢ CodeSubmission.run()      â”‚
â”‚  every     â”‚     â”‚  â€¢ Docker container exec     â”‚
â”‚  500ms     â”‚     â”‚  â€¢ Collect stdout/stderr     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚  â€¢ Set done=true             â”‚
      â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 4. Poll: POST /check {uuid}
      â–¼                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
â”‚  CodeExecutionService.check()       â”‚
â”‚  â€¢ Lookup UUID in HashMap           â”‚
â”‚  â€¢ Return status + results          â”‚
â”‚  â€¢ Remove if FINISHED               â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 5. Return RunResult
      â”‚    status: RUNNING | FINISHED | NONEXISTENT
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend  â”‚
â”‚  Displays  â”‚
â”‚  Output    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Background: @Scheduled cleanup every 30s removes old executions
```

#### AI Agent Flow (with Autonomous Tool Invocation)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User     â”‚
â”‚  Chat UI   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 1. POST /llm/message {messages, code, result}
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    LLMController.messagePrompt()         â”‚
â”‚    â€¢ Convert UserChat to ChatMessages    â”‚
â”‚    â€¢ Inject code context between msgs    â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 2. Call GeminiService
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    GeminiService.messageModel()          â”‚
â”‚    â€¢ Delegates to assistant              â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 3. Call agent
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CodeHelperAssistant.chat()                    â”‚
â”‚    (@AiService - LangChain4j agent)              â”‚
â”‚    â€¢ Analyzes context + chat history             â”‚
â”‚    â€¢ Reasons about user's problem                â”‚
â”‚    â€¢ Decides if tool invocation needed           â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â”‚ IF agent decides to test code:
      â”‚ 4. Agent autonomously invokes tool
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    CodeExecutionTools.executeCode()              â”‚
â”‚    (@Tool method)                                â”‚
â”‚    â€¢ Creates CodeSubmission                      â”‚
â”‚    â€¢ Submits to CodeExecutionService (same queue)â”‚
â”‚    â€¢ Polls for results (20 min timeout)          â”‚
â”‚    â€¢ Returns truncated output (1MB limit)        â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 5. Tool returns result to agent
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Agent interprets tool result                  â”‚
â”‚    â€¢ Verifies if fix worked                      â”‚
â”‚    â€¢ Generates debugging advice                  â”‚
â”‚    â€¢ Suggests corrected code                     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚ 6. Return response
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend  â”‚
â”‚  Displays  â”‚
â”‚  Markdown  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

#### Frontend (`cr-frontend/src/`)
- `App.jsx` - Main app with polling logic
- `components/CodeEditor.jsx`, `Terminal.jsx`, `ChatInterface.jsx` - UI components
- `components/SyntaxHighlighter.jsx` - Regex-based highlighting

#### Backend (`src/main/java/com/cr/coderunner/`)
- `controller/IDEController.java` - `/submit`, `/check` endpoints
- `controller/LLMController.java` - `/llm/message` endpoint
- `model/CodeSubmission.java` - Docker execution engine
- `service/CodeExecutionService.java` - **10-worker thread pool queue manager**
- `service/CodeHelperAssistant.java` - **@AiService LangChain4j agent**
- `service/CodeExecutionTools.java` - **@Tool methods for agent**
- `service/LLMConfig.java` - ChatModel bean config

## Prerequisites

- **Docker**, **Java 21+**, **Node.js v18+**, **Maven**
- **Google Gemini API Key** for AI assistant

## Installation

### 1. Clone Repository
```bash
git clone https://github.com/yourusername/CodeRunner.git && cd CodeRunner
```

### 2. Backend Setup
```bash
# Set gemini.api.key in application.properties or export GEMINI_API_KEY
echo "gemini.api.key=your_api_key_here" >> src/main/resources/application.properties
mvn clean install && mvn spring-boot:run
```

### 3. Frontend Setup
```bash
cd cr-frontend
npm install
echo "VITE_API_URL=http://localhost:8080" > .env
npm run dev
```

### 4. Docker Setup
```bash
docker pull alpine:latest python:3.12-alpine eclipse-temurin:21-alpine
```

## Usage

### Running Code
1. Open `http://localhost:5173`, select language
2. Write code (or load template), optionally add stdin input
3. Click "RUN" â†’ polls for results â†’ view output/errors
4. Click "STOP" to terminate if needed

### Using Code_Helper
1. Switch to "CODE_HELPER" tab
2. Ask questions about your code
3. Agent analyzes context, may autonomously test code via tools
4. Receive debugging suggestions with markdown formatting
5. Chat history persists across tab switches

## API Endpoints

### Code Execution Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/submit` | Submit code for execution, returns UUID |
| POST | `/check` | Check execution status by UUID (returns RunResult) |
| GET | `/check_queue` | List all active executions in queue (debug endpoint) |
| GET | `/check/{id}` | Check if submission exists (legacy) |
| GET | `/get_template` | Get code template for language |
| GET | `/supported` | Get list of supported languages |

### AI Assistant Endpoints
| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/llm/message` | Send message to AI with code context |
| POST | `/llm/ask` | Simple prompt endpoint (testing) |

### Health & Monitoring
| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/health` | Basic health check |
| GET | `/actuator/health` | Detailed health status |
| GET | `/actuator/prometheus` | Prometheus metrics |

### Example Request
```bash
# Submit code â†’ returns UUID
curl -X POST http://localhost:8080/submit -H "Content-Type: application/json" \
  -d '{"code": "print(\"Hello\")", "language": "Python", "problem": "test", "input": ""}'

# Check status â†’ returns RunResult
curl -X POST http://localhost:8080/check -H "Content-Type: application/json" \
  -d '"a1b2c3d4-e5f6-7890-abcd-ef1234567890"'

# Response: {"success": true, "runtime": 0.123, "output": "Hello\n", "status": "FINISHED"}

# Ask AI (agent may autonomously test code)
curl -X POST http://localhost:8080/llm/message -H "Content-Type: application/json" \
  -d '{
    "messages": [{"role": "user", "content": "Why is my code not working?"}],
    "code": {"code": "print(x)", "language": "Python"},
    "result": {"success": false, "error": "NameError: name '\''x'\'' is not defined"}
  }'

# Check queue
curl http://localhost:8080/check_queue
```

## Project Structure

```
CodeRunner/
â”œâ”€â”€ cr-frontend/                 # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ Alert.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatInterface.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CodeEditor.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ExecutingAnimation.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ SyntaxHighlighter.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Terminal.jsx
â”‚   â”‚   â”‚   â””â”€â”€ TextWindow.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main application
â”‚   â”‚   â”œâ”€â”€ App.css             # Styles including custom scrollbars
â”‚   â”‚   â””â”€â”€ main.jsx            # Entry point
â”‚   â”œâ”€â”€ public/                 # Static assets
â”‚   â”œâ”€â”€ .env                    # Environment variables (API URL)
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ src/main/java/com/cr/coderunner/
â”‚   â”œâ”€â”€ controller/             # REST controllers
â”‚   â”‚   â”œâ”€â”€ IDEController.java
â”‚   â”‚   â”œâ”€â”€ LLMController.java
â”‚   â”‚   â”œâ”€â”€ HealthController.java
â”‚   â”‚   â””â”€â”€ ProblemController.java
â”‚   â”œâ”€â”€ model/                  # Domain models
â”‚   â”‚   â”œâ”€â”€ CodeSubmission.java
â”‚   â”‚   â””â”€â”€ CodeExecution.java
â”‚   â”œâ”€â”€ service/                # Business logic & AI integration
â”‚   â”‚   â”œâ”€â”€ CodeExecutionService.java    # Execution queue manager
â”‚   â”‚   â”œâ”€â”€ CodeExecutionTools.java      # LangChain4j agent tools
â”‚   â”‚   â”œâ”€â”€ CodeHelperAssistant.java     # LangChain4j @AiService agent
â”‚   â”‚   â”œâ”€â”€ LLMConfig.java               # ChatModel Spring Bean config
â”‚   â”‚   â”œâ”€â”€ GeminiService.java           # AI service facade
â”‚   â”‚   â”œâ”€â”€ UserData.java                # In-memory storage (legacy)
â”‚   â”‚   â””â”€â”€ WebConfig.java               # CORS configuration
â”‚   â””â”€â”€ dto/                    # Data transfer objects
â”‚       â”œâ”€â”€ RunResult.java
â”‚       â”œâ”€â”€ UserChat.java
â”‚       â””â”€â”€ ChatBlock.java
â”œâ”€â”€ .test/                      # Temporary execution files (git-ignored)
â”œâ”€â”€ .env                        # Environment variables (API keys)
â”œâ”€â”€ Dockerfile                  # Production Docker image
â”œâ”€â”€ docker-entrypoint.sh        # Docker startup script
â”œâ”€â”€ pom.xml                     # Maven configuration
â”œâ”€â”€ CLAUDE.md                   # Development guidelines
â””â”€â”€ README.md
```

## Development

### Running Tests
```bash
mvn test                           # Backend
cd cr-frontend && npm run lint     # Frontend
```

### Building for Production
```bash
# Backend
mvn clean package && java -jar target/CodeRunner-0.0.1-SNAPSHOT.jar

# Frontend
cd cr-frontend && npm run build    # outputs to dist/

# Docker
docker build -t coderunner .
docker run --privileged --cgroupns=host -p 8080:8080 \
  -e gemini.api.key=your_api_key_here coderunner
```

## Roadmap

### Recently Completed
- [x] LangChain4j agent framework with @AiService and @Tool
- [x] Agent autonomous code testing via tool invocation
- [x] Asynchronous execution queue (10-worker thread pool)
- [x] UUID-based polling for non-blocking execution
- [x] Scheduled cleanup of stale executions

### Planned Features
- [ ] C++/JavaScript/TypeScript language support
- [ ] SQL database migration (currently in-memory)
- [ ] User authentication and session management
- [ ] Problem/challenge system
- [ ] Code sharing with shareable links

## Technical Details

### Execution Safety
- 60-second timeout, 1MB output limit (backend), 500KB (frontend)
- Docker containerization for isolated execution
- Multi-threaded stdout/stderr readers prevent deadlocks
- Automatic cleanup of temp files and containers
- Scheduled task removes stale executions (60s old, runs every 30s)

### Agent Safety & Constraints

- **Read-Only Design**: Agent suggests fixes, user manually applies (no direct code modification)
- **Sparing Tool Use**: System prompt limits autonomous testing frequency
- **Output Limits**: 1MB backend, 1000 chars for LLM context (prevents token overflow)
- **Pattern**: Agent analyzes â†’ tests hypothesis via tool â†’ suggests verified fix

```
Agent analyzes â†’ Tests via tool â†’ Verifies fix â†’ Suggests to user
```

### Docker Execution Details

```bash
# Python
docker run --name <uuid> --rm -v /host:/sandbox python:3.12-alpine \
  sh -c "python3 sandbox/code.py < sandbox/input.txt"

# C
docker run --name <uuid> --rm -v /host:/sandbox alpine:latest \
  sh -c "apk add gcc musl-dev && gcc sandbox/code.c -o sandbox/main && ./sandbox/main"

# Java
docker run --name <uuid> --rm -v /host:/sandbox eclipse-temurin:21-alpine \
  sh -c "java sandbox/code.java < sandbox/input.txt"
```

### Execution Queue Architecture

```java
// 10-worker thread pool
private final ExecutorService executor = Executors.newFixedThreadPool(10);
private final ConcurrentHashMap<String, CodeExecution> results;

String uuid = executionService.execute(new CodeExecution(submission));
RunResult result = executionService.checkExecution(uuid);
// Status: "RUNNING" | "FINISHED" | "NONEXISTENT"
```

**Lifecycle**: Submit (UUID) â†’ Worker executes â†’ Store in HashMap â†’ Poll â†’ Cleanup

```java
@Scheduled(fixedRate = 30_000) // Cleanup every 30s
public void cleanExecutions() {
    // Removes executions older than 60 seconds
}
```

### AI Integration (LangChain4j Agent Framework)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LangChain4j Spring Boot Auto-Configuration              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  @AiService Interface (CodeHelperAssistant)              â”‚
â”‚  â€¢ Interface with @SystemMessage + chat() method         â”‚
â”‚  â€¢ Auto-implemented by LangChain4j                       â”‚
â”‚                                                           â”‚
â”‚  @Tool Methods (CodeExecutionTools)                      â”‚
â”‚  â€¢ executeCode(code, language, input) â†’ String           â”‚
â”‚  â€¢ Agent invokes autonomously during reasoning           â”‚
â”‚                                                           â”‚
â”‚  ChatModel Bean (LLMConfig)                              â”‚
â”‚  â€¢ GoogleAiGeminiChatModel (gemini-2.5-flash)           â”‚
â”‚  â€¢ Auto-injected into agent                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dependencies**:
```xml
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-spring-boot-starter</artifactId>
    <version>1.11.0-beta19</version>
</dependency>
<dependency>
    <groupId>dev.langchain4j</groupId>
    <artifactId>langchain4j-google-ai-gemini</artifactId>
    <version>1.11.0</version>
</dependency>
```

### Supported Languages

| Language | Execution Method | Docker Image | Status |
|----------|------------------|--------------|--------|
| Java | eclipse-temurin:21-alpine | Yes | âœ… Fully Supported |
| Python | python:3.12-alpine | Yes | âœ… Fully Supported |
| C | alpine:latest + GCC | Yes | âœ… Fully Supported |
| C++ | alpine:latest + G++ | Planned | ğŸš§ In Development |

## Configuration

### Environment Variables

```bash
# Backend (application.properties)
gemini.api.key=your_gemini_api_key_here

# Frontend (cr-frontend/.env)
VITE_API_URL=http://localhost:8080
```

**CORS**: Allows `http://localhost:5173` (configured in `WebConfig.java`)

## Contributing

Fork â†’ Create branch â†’ Commit â†’ Push â†’ Open PR

## Known Issues & TODOs

- Fine-tune agent prompt and add token usage tracking
- Optimize Docker image caching and add rate limiting
- Remove debug print statements
- Migrate to SQL database
- Add user authentication

## License

This project is open source and available under the [MIT License](LICENSE).

## Acknowledgments

Built with **Spring Boot**, **React**, **Docker**, **Google Gemini AI**, and **LangChain4j**. Inspired by LeetCode and HackerRank.

---

**Note**: Active development. AI assistant requires **Gemini API key**. Backend uses **async execution queue** (10-worker thread pool) and **LangChain4j agent framework** with autonomous code testing.
